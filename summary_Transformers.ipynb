{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oackTwIu6iql",
        "outputId": "077ff0ad-86e0-4320-c382-2439818564bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hVoN3jj9giC",
        "outputId": "81de6b29-3cc2-4cbd-9be3-48afe17a470a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygNeuZxALsgD",
        "outputId": "cf30e172-f48f-4038-d1eb-07bb97636cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (0.1.97)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJOUkKi0-lHl"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0R3U_atz6C_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_path = '/content/drive/MyDrive/Summary/train.csv'\n",
        "test_path = '/content/drive/MyDrive/Summary/test.csv'\n",
        "val_path = '/content/drive/MyDrive/Summary/validation.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isjUomlT9C6f"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "val_df = pd.read_csv(val_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCLnL_m09tay",
        "outputId": "8111742b-4e17-49a9-9591-cfa5a6aea355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (287113, 3)\n",
            "Test data:  (11490, 3)\n",
            "Val data:  (13368, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train data:\", train_df.shape)\n",
        "print(\"Test data: \", test_df.shape)\n",
        "print(\"Val data: \", val_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uGhgNHH2hTzi",
        "outputId": "a9b1bcd9-26ea-405b-9780-4a696d2858dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id  \\\n",
              "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
              "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
              "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
              "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
              "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
              "\n",
              "                                             article  \\\n",
              "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
              "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
              "2  A drunk driver who killed a young woman in a h...   \n",
              "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
              "4  Fleetwood are the only team still to have a 10...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Bishop John Folda, of North Dakota, is taking ...  \n",
              "1  Criminal complaint: Cop used his role to help ...  \n",
              "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
              "3  Nina dos Santos says Europe must be ready to a...  \n",
              "4  Fleetwood top of League One after 2-0 win at S...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47230162-193a-47b3-bc89-b36a7361afcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
              "      <td>A drunk driver who killed a young woman in a h...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
              "      <td>Fleetwood are the only team still to have a 10...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47230162-193a-47b3-bc89-b36a7361afcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47230162-193a-47b3-bc89-b36a7361afcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47230162-193a-47b3-bc89-b36a7361afcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mpVcSNVWheQz",
        "outputId": "692fc66c-9ebc-4eb0-865e-4aaa4c8c2662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id  \\\n",
              "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
              "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
              "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
              "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
              "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
              "\n",
              "                                             article  \\\n",
              "0  Ever noticed how plane seats appear to be gett...   \n",
              "1  A drunk teenage boy had to be rescued by secur...   \n",
              "2  Dougie Freedman is on the verge of agreeing a ...   \n",
              "3  Liverpool target Neto is also wanted by PSG an...   \n",
              "4  Bruce Jenner will break his silence in a two-h...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Experts question if  packed out planes are put...  \n",
              "1  Drunk teenage boy climbed into lion enclosure ...  \n",
              "2  Nottingham Forest are close to extending Dougi...  \n",
              "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
              "4  Tell-all interview with the reality TV star, 6...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c38d1a0c-c10f-44a9-8038-b2d744231e12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
              "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
              "      <td>Experts question if  packed out planes are put...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
              "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
              "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
              "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
              "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
              "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
              "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
              "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
              "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38d1a0c-c10f-44a9-8038-b2d744231e12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c38d1a0c-c10f-44a9-8038-b2d744231e12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c38d1a0c-c10f-44a9-8038-b2d744231e12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zr4EIxbhhiTY",
        "outputId": "fcae6364-5448-485f-a778-9215db2c5659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id  \\\n",
              "0  61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3   \n",
              "1  21c0bd69b7e7df285c3d1b1cf56d4da925980a68   \n",
              "2  56f340189cd128194b2e7cb8c26bb900e3a848b4   \n",
              "3  00a665151b89a53e5a08a389df8334f4106494c2   \n",
              "4  9f6fbd3c497c4d28879bebebea220884f03eb41a   \n",
              "\n",
              "                                             article  \\\n",
              "0  Sally Forrest, an actress-dancer who graced th...   \n",
              "1  A middle-school teacher in China has inked hun...   \n",
              "2  A man convicted of killing the father and sist...   \n",
              "3  Avid rugby fan Prince Harry could barely watch...   \n",
              "4  A Triple M Radio producer has been inundated w...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Sally Forrest, an actress-dancer who graced th...  \n",
              "1  Works include pictures of Presidential Palace ...  \n",
              "2  Iftekhar Murtaza, 29, was convicted a year ago...  \n",
              "3  Prince Harry in attendance for England's crunc...  \n",
              "4  Nick Slater's colleagues uploaded a picture to...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36f4650f-9d52-445f-92eb-6020a5197a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3</td>\n",
              "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
              "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21c0bd69b7e7df285c3d1b1cf56d4da925980a68</td>\n",
              "      <td>A middle-school teacher in China has inked hun...</td>\n",
              "      <td>Works include pictures of Presidential Palace ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56f340189cd128194b2e7cb8c26bb900e3a848b4</td>\n",
              "      <td>A man convicted of killing the father and sist...</td>\n",
              "      <td>Iftekhar Murtaza, 29, was convicted a year ago...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00a665151b89a53e5a08a389df8334f4106494c2</td>\n",
              "      <td>Avid rugby fan Prince Harry could barely watch...</td>\n",
              "      <td>Prince Harry in attendance for England's crunc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9f6fbd3c497c4d28879bebebea220884f03eb41a</td>\n",
              "      <td>A Triple M Radio producer has been inundated w...</td>\n",
              "      <td>Nick Slater's colleagues uploaded a picture to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36f4650f-9d52-445f-92eb-6020a5197a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36f4650f-9d52-445f-92eb-6020a5197a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36f4650f-9d52-445f-92eb-6020a5197a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "#start process_review\n",
        "def processReview(review):\n",
        "    #Convert to lower case\n",
        "    review = review.lower()\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Removing numbers\n",
        "    review = re.sub('[0-9]', '', review)\n",
        "    #Remove additional white spaces\n",
        "    review = re.sub('[\\s]+', ' ', review)\n",
        "    #Replace #word with word\n",
        "    review = re.sub(r'#([^\\s]+)', r'\\1', review)\n",
        "    #trim\n",
        "    review = review.strip('\\'\"')\n",
        "    review = review.strip('.,')\n",
        "\n",
        "    return review\n"
      ],
      "metadata": {
        "id": "J70GOqba8qe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_article = []\n",
        "for review in val_df['article']:\n",
        "  processed_article.append(processReview(review))\n"
      ],
      "metadata": {
        "id": "aua6WkBuB-qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_highlights = []\n",
        "for review in val_df['highlights']:\n",
        "  processed_highlights.append(processReview(review))"
      ],
      "metadata": {
        "id": "J4C0BxkpEHF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['Article'] = processed_article\n",
        "val_df['Highlights'] = processed_highlights"
      ],
      "metadata": {
        "id": "B-onjpYa831P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train_df[['article', 'highlights']]\n",
        "df_test = test_df[['article', 'highlights']]\n",
        "df_val = val_df[['Article', 'Highlights']]"
      ],
      "metadata": {
        "id": "6Wi2bGkThril"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWaJ_Ob83Dt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxSBx4G3_RjH"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP8LQi2q-lNF"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWwUPMWW-mwB"
      },
      "outputs": [],
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5aXAcz2-BXF"
      },
      "outputs": [],
      "source": [
        "SRC = Field(tokenize = tokenize_en,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            fix_length = 800,\n",
        "            lower = True,\n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            fix_length = 800,\n",
        "            lower = True,\n",
        "            batch_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkBkuEZk_Vzh"
      },
      "outputs": [],
      "source": [
        "fields = [('Article', SRC),('Highlights',TRG)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgZjRjdYonv9"
      },
      "outputs": [],
      "source": [
        "example = [data.Example.fromlist([df_val.Article[i],df_val.Highlights[i]], fields) for i in range(df_val.shape[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKVdZ9eh_3cz"
      },
      "outputs": [],
      "source": [
        "CodeDataset = data.Dataset(example, fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeEhuweaAB6N",
        "outputId": "5c59b105-f3ea-4229-8bb5-ca237b044cd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Article': ['sally',\n",
              "  'forrest',\n",
              "  'an',\n",
              "  'actressdancer',\n",
              "  'who',\n",
              "  'graced',\n",
              "  'the',\n",
              "  'silver',\n",
              "  'screen',\n",
              "  'throughout',\n",
              "  'the',\n",
              "  's',\n",
              "  'and',\n",
              "  's',\n",
              "  'in',\n",
              "  'mgm',\n",
              "  'musicals',\n",
              "  'and',\n",
              "  'films',\n",
              "  'such',\n",
              "  'as',\n",
              "  'the',\n",
              "  'noir',\n",
              "  'while',\n",
              "  'the',\n",
              "  'city',\n",
              "  'sleeps',\n",
              "  'died',\n",
              "  'on',\n",
              "  'march',\n",
              "  'at',\n",
              "  'her',\n",
              "  'home',\n",
              "  'in',\n",
              "  'beverly',\n",
              "  'hills',\n",
              "  'california',\n",
              "  'forrest',\n",
              "  'whose',\n",
              "  'birth',\n",
              "  'name',\n",
              "  'was',\n",
              "  'katherine',\n",
              "  'feeney',\n",
              "  'was',\n",
              "  'and',\n",
              "  'had',\n",
              "  'long',\n",
              "  'battled',\n",
              "  'cancer',\n",
              "  'her',\n",
              "  'publicist',\n",
              "  'judith',\n",
              "  'goffin',\n",
              "  'announced',\n",
              "  'the',\n",
              "  'news',\n",
              "  'thursday',\n",
              "  'scroll',\n",
              "  'down',\n",
              "  'for',\n",
              "  'video',\n",
              "  'actress',\n",
              "  'sally',\n",
              "  'forrest',\n",
              "  'was',\n",
              "  'in',\n",
              "  'the',\n",
              "  'ida',\n",
              "  'lupinodirected',\n",
              "  'film',\n",
              "  'hard',\n",
              "  'fast',\n",
              "  'and',\n",
              "  'beautiful',\n",
              "  'left',\n",
              "  'and',\n",
              "  'the',\n",
              "  'fritz',\n",
              "  'lang',\n",
              "  'movie',\n",
              "  'while',\n",
              "  'the',\n",
              "  'city',\n",
              "  'sleeps',\n",
              "  'a',\n",
              "  'san',\n",
              "  'diego',\n",
              "  'native',\n",
              "  'forrest',\n",
              "  'became',\n",
              "  'a',\n",
              "  'protege',\n",
              "  'of',\n",
              "  'hollywood',\n",
              "  'trailblazer',\n",
              "  'ida',\n",
              "  'lupino',\n",
              "  'who',\n",
              "  'cast',\n",
              "  'her',\n",
              "  'in',\n",
              "  'starring',\n",
              "  'roles',\n",
              "  'in',\n",
              "  'films',\n",
              "  'including',\n",
              "  'the',\n",
              "  'critical',\n",
              "  'and',\n",
              "  'commercial',\n",
              "  'success',\n",
              "  'not',\n",
              "  'wanted',\n",
              "  'never',\n",
              "  'fear',\n",
              "  'and',\n",
              "  'hard',\n",
              "  'fast',\n",
              "  'and',\n",
              "  'beautiful',\n",
              "  'some',\n",
              "  'of',\n",
              "  'forrests',\n",
              "  'other',\n",
              "  'film',\n",
              "  'credits',\n",
              "  'included',\n",
              "  'bannerline',\n",
              "  'son',\n",
              "  'of',\n",
              "  'sinbad',\n",
              "  'and',\n",
              "  'excuse',\n",
              "  'my',\n",
              "  'dust',\n",
              "  'according',\n",
              "  'to',\n",
              "  'her',\n",
              "  'imdb',\n",
              "  'page',\n",
              "  'the',\n",
              "  'page',\n",
              "  'also',\n",
              "  'indicates',\n",
              "  'forrest',\n",
              "  'was',\n",
              "  'in',\n",
              "  'multiple',\n",
              "  'climax',\n",
              "  'and',\n",
              "  'rawhide',\n",
              "  'television',\n",
              "  'episodes',\n",
              "  'forrest',\n",
              "  'appeared',\n",
              "  'as',\n",
              "  'herself',\n",
              "  'in',\n",
              "  'an',\n",
              "  'episode',\n",
              "  'of',\n",
              "  'the',\n",
              "  'ed',\n",
              "  'sullivan',\n",
              "  'show',\n",
              "  'and',\n",
              "  'three',\n",
              "  'episodes',\n",
              "  'of',\n",
              "  'the',\n",
              "  'dinah',\n",
              "  'shore',\n",
              "  'chevy',\n",
              "  'show',\n",
              "  'her',\n",
              "  'imdb',\n",
              "  'page',\n",
              "  'says',\n",
              "  'she',\n",
              "  'also',\n",
              "  'starred',\n",
              "  'in',\n",
              "  'a',\n",
              "  'broadway',\n",
              "  'production',\n",
              "  'of',\n",
              "  'the',\n",
              "  'seven',\n",
              "  'year',\n",
              "  'itch',\n",
              "  'city',\n",
              "  'news',\n",
              "  'service',\n",
              "  'reported',\n",
              "  'that',\n",
              "  'other',\n",
              "  'stage',\n",
              "  'credits',\n",
              "  'included',\n",
              "  'as',\n",
              "  'you',\n",
              "  'like',\n",
              "  'it',\n",
              "  'no',\n",
              "  'no',\n",
              "  'nanette',\n",
              "  'and',\n",
              "  'damn',\n",
              "  'yankees',\n",
              "  'forrest',\n",
              "  'married',\n",
              "  'writerproducer',\n",
              "  'milo',\n",
              "  'frank',\n",
              "  'in',\n",
              "  'he',\n",
              "  'died',\n",
              "  'in',\n",
              "  'she',\n",
              "  'is',\n",
              "  'survived',\n",
              "  'by',\n",
              "  'her',\n",
              "  'niece',\n",
              "  'sharon',\n",
              "  'durham',\n",
              "  'and',\n",
              "  'nephews',\n",
              "  'michael',\n",
              "  'and',\n",
              "  'mark',\n",
              "  'feeney',\n",
              "  'career',\n",
              "  'a',\n",
              "  'san',\n",
              "  'diego',\n",
              "  'native',\n",
              "  'forrest',\n",
              "  'became',\n",
              "  'a',\n",
              "  'protege',\n",
              "  'of',\n",
              "  'hollywood',\n",
              "  'trailblazer',\n",
              "  'ida',\n",
              "  'lupino',\n",
              "  'who',\n",
              "  'cast',\n",
              "  'her',\n",
              "  'in',\n",
              "  'starring',\n",
              "  'roles',\n",
              "  'in',\n",
              "  'films'],\n",
              " 'Highlights': ['sally',\n",
              "  'forrest',\n",
              "  'an',\n",
              "  'actressdancer',\n",
              "  'who',\n",
              "  'graced',\n",
              "  'the',\n",
              "  'silver',\n",
              "  'screen',\n",
              "  'throughout',\n",
              "  'the',\n",
              "  's',\n",
              "  'and',\n",
              "  's',\n",
              "  'in',\n",
              "  'mgm',\n",
              "  'musicals',\n",
              "  'and',\n",
              "  'films',\n",
              "  'died',\n",
              "  'on',\n",
              "  'march',\n",
              "  'forrest',\n",
              "  'whose',\n",
              "  'birth',\n",
              "  'name',\n",
              "  'was',\n",
              "  'katherine',\n",
              "  'feeney',\n",
              "  'had',\n",
              "  'long',\n",
              "  'battled',\n",
              "  'cancer',\n",
              "  'a',\n",
              "  'san',\n",
              "  'diego',\n",
              "  'native',\n",
              "  'forrest',\n",
              "  'became',\n",
              "  'a',\n",
              "  'protege',\n",
              "  'of',\n",
              "  'hollywood',\n",
              "  'trailblazer',\n",
              "  'ida',\n",
              "  'lupino',\n",
              "  'who',\n",
              "  'cast',\n",
              "  'her',\n",
              "  'in',\n",
              "  'starring',\n",
              "  'roles',\n",
              "  'in',\n",
              "  'films']}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "vars(CodeDataset.examples[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkzGdjXZAG-2"
      },
      "outputs": [],
      "source": [
        "(train, test, val) = CodeDataset.split(split_ratio=[0.80, 0.10, 0.10], random_state=random.seed(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpc2SpswAM3J"
      },
      "outputs": [],
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG0-6oKzBQ1t",
        "outputId": "1365f5eb-335a-43c4-9168-25e64e252983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of SRC vocab:  67036\n",
            "size of TRG vocab:  20299\n"
          ]
        }
      ],
      "source": [
        "print(\"size of SRC vocab: \", len(SRC.vocab))\n",
        "print('size of TRG vocab: ', len(TRG.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGd07hbUBd1h"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFongAfSBp-L"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 12\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, val, test),\n",
        "    sort = False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ImLedZ8Ol1V"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hid_dim,\n",
        "                 n_layers,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device,\n",
        "                 max_length = 800):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        #pos = [batch size, src len]\n",
        "\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJSpOIruOrT-"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVj2cG-bO4cx"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hid_dim % n_heads == 0\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "\n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "\n",
        "        #x = [batch size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        #x = [batch size, query len, hid dim]\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA3PdqZwO6qo"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #x = [batch size, seq len, hid dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        #x = [batch size, seq len, pf dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        #x = [batch size, seq len, hid dim]\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9q5ukPYO-Xw"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim,\n",
        "                 hid_dim,\n",
        "                 n_layers,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device,\n",
        "                 max_length = 800):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        #pos = [batch size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXTXfD7aPItR"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "\n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "\n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjx8CoTaPOyu"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 decoder,\n",
        "                 src_pad_idx,\n",
        "                 trg_pad_idx,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(SRC.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQL82HG_eJ8L",
        "outputId": "c43fe695-4a3c-476e-eadb-41f23a93bc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67036"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhWg4vahPUHD"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM,\n",
        "              ENC_LAYERS,\n",
        "              ENC_HEADS,\n",
        "              ENC_PF_DIM,\n",
        "              ENC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggFdUthRPs9a"
      },
      "outputs": [],
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM16bNPrPyYA",
        "outputId": "6ae3ecb5-c382-4a47-af0f-18264ac4cb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 31,937,867 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7yLzZ0LP4jd"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK9Ud77ACwSL"
      },
      "outputs": [],
      "source": [
        "model.apply(initialize_weights);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N1ZbpniC0yB"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnXTFZMfC6Ge"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZoLagKQQKUh"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.Article\n",
        "        trg = batch.Highlights\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwiD11IQQSks"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.Article\n",
        "            trg = batch.Highlights\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBldrkgZQZaN"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBL0qrN0QeKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d412694-8f22-41bd-d0c8-0396723c962c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 8m 13s\n",
            "\tTrain Loss: 6.966 | Train PPL: 1059.964\n",
            "\t Val. Loss: 6.183 |  Val. PPL: 484.530\n",
            "Epoch: 02 | Time: 8m 15s\n",
            "\tTrain Loss: 6.094 | Train PPL: 442.982\n",
            "\t Val. Loss: 5.828 |  Val. PPL: 339.632\n",
            "Epoch: 03 | Time: 8m 15s\n",
            "\tTrain Loss: 5.553 | Train PPL: 257.988\n",
            "\t Val. Loss: 5.662 |  Val. PPL: 287.734\n",
            "Epoch: 04 | Time: 8m 15s\n",
            "\tTrain Loss: 5.063 | Train PPL: 158.090\n",
            "\t Val. Loss: 5.648 |  Val. PPL: 283.650\n",
            "Epoch: 05 | Time: 8m 15s\n",
            "\tTrain Loss: 4.599 | Train PPL:  99.394\n",
            "\t Val. Loss: 5.741 |  Val. PPL: 311.342\n",
            "Epoch: 06 | Time: 8m 15s\n",
            "\tTrain Loss: 4.164 | Train PPL:  64.314\n",
            "\t Val. Loss: 5.889 |  Val. PPL: 360.982\n",
            "Epoch: 07 | Time: 8m 15s\n",
            "\tTrain Loss: 3.761 | Train PPL:  43.010\n",
            "\t Val. Loss: 6.133 |  Val. PPL: 460.591\n",
            "Epoch: 08 | Time: 8m 15s\n",
            "\tTrain Loss: 3.404 | Train PPL:  30.088\n",
            "\t Val. Loss: 6.356 |  Val. PPL: 576.195\n",
            "Epoch: 09 | Time: 8m 15s\n",
            "\tTrain Loss: 3.092 | Train PPL:  22.030\n",
            "\t Val. Loss: 6.630 |  Val. PPL: 757.225\n",
            "Epoch: 10 | Time: 8m 15s\n",
            "\tTrain Loss: 2.833 | Train PPL:  17.000\n",
            "\t Val. Loss: 6.938 |  Val. PPL: 1031.058\n",
            "Epoch: 11 | Time: 8m 16s\n",
            "\tTrain Loss: 2.608 | Train PPL:  13.571\n",
            "\t Val. Loss: 7.112 |  Val. PPL: 1226.477\n",
            "Epoch: 12 | Time: 8m 15s\n",
            "\tTrain Loss: 2.427 | Train PPL:  11.323\n",
            "\t Val. Loss: 7.373 |  Val. PPL: 1592.952\n",
            "Epoch: 13 | Time: 8m 16s\n",
            "\tTrain Loss: 2.269 | Train PPL:   9.668\n",
            "\t Val. Loss: 7.646 |  Val. PPL: 2092.339\n",
            "Epoch: 14 | Time: 8m 16s\n",
            "\tTrain Loss: 2.138 | Train PPL:   8.480\n",
            "\t Val. Loss: 7.851 |  Val. PPL: 2568.274\n",
            "Epoch: 15 | Time: 8m 16s\n",
            "\tTrain Loss: 2.018 | Train PPL:   7.523\n",
            "\t Val. Loss: 8.021 |  Val. PPL: 3043.206\n",
            "Epoch: 16 | Time: 8m 16s\n",
            "\tTrain Loss: 1.922 | Train PPL:   6.834\n",
            "\t Val. Loss: 8.151 |  Val. PPL: 3466.856\n",
            "Epoch: 17 | Time: 8m 16s\n",
            "\tTrain Loss: 1.828 | Train PPL:   6.222\n",
            "\t Val. Loss: 8.470 |  Val. PPL: 4769.580\n",
            "Epoch: 18 | Time: 8m 16s\n",
            "\tTrain Loss: 1.753 | Train PPL:   5.774\n",
            "\t Val. Loss: 8.575 |  Val. PPL: 5299.809\n",
            "Epoch: 19 | Time: 8m 16s\n",
            "\tTrain Loss: 1.683 | Train PPL:   5.383\n",
            "\t Val. Loss: 8.775 |  Val. PPL: 6469.297\n",
            "Epoch: 20 | Time: 8m 15s\n",
            "\tTrain Loss: 1.619 | Train PPL:   5.049\n",
            "\t Val. Loss: 8.969 |  Val. PPL: 7854.151\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = [42,\t16.3,\t40.1]\n",
        "recall = [41.62,\t16.02,\t39.56]\n",
        "f1score = [42.07,\t16.35,\t40.1]"
      ],
      "metadata": {
        "id": "4vRST3ZvRWw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj5E8ACj0pmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7879b8b5-f861-4cfd-ee4c-4367c3466118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 5.664 | Test PPL: 288.425 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut6-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:], attention"
      ],
      "metadata": {
        "id": "dvOwb6p3e41y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PzSBwan1jSu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'],\n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels(['']+translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JnALDzu1qal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e061d17-a978-4935-ce30-1b7a6f80c804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['radamel', 'falcao', 'has', 'been', 'reduced', 'to', 'tears', 'by', 'his', 'manchester', 'united', 'nightmare', 'according', 'to', 'the', 'colombia', 'star', '’s', 'former', 'agent', 'silvano', 'espindola', 'revealed', 'that', 'falcao', 'phoned', 'him', 'from', 'old', 'trafford', 'last', 'week', 'before', 'he', 'was', 'made', 'to', 'play', 'for', 'the', 'under', 's', 'against', 'tottenham', 'and', 'admitted', 'he', 'felt', '‘', 'weird', '’', 'about', 'the', 'situation', 'the', 'yearold', 'striker', 'also', 'expressed', 'fears', 'that', 'he', 'risked', 'a', 'recurrence', 'of', 'his', 'serious', 'knee', 'injury', 'by', 'playing', 'against', 'lowergrade', 'opposition', 'radamel', 'falcao', 'has', 'endured', 'a', 'torrid', 'time', 'at', 'manchester', 'united', 'of', 'late', 'and', 'has', 'been', 'in', 'tears', 'at', 'his', 'situation', 'falcao', 'played', 'for', 'uniteds', 'under', 's', 'but', 'admitted', 'to', 'his', 'former', 'agent', 'that', 'he', 'is', 'scared', 'of', 'getting', 'injured', 'falcao', 'lined', 'up', 'for', 'uniteds', 'development', 'side', 'against', 'tottenham', 'but', 'failed', 'to', 'make', 'an', 'impact', 'on', 'the', 'game', 'falcao', 'is', 'earning', '£', 'aweek', 'during', 'his', 'loan', 'to', 'united', 'from', 'monaco', 'but', 'it', 'looks', 'increasingly', 'unlikely', 'that', 'louis', 'van', 'gaal', 'will', 'sanction', 'a', '£', 'million', 'deal', 'to', 'make', 'the', 'move', 'permanent', 'at', 'the', 'end', 'of', 'the', 'season', 'the', 'former', 'porto', 'and', 'atletico', 'madrid', 'man', 'has', 'only', 'scored', 'four', 'goals', 'for', 'united', 'and', 'has', 'not', 'started', 'a', 'game', 'for', 'three', 'weeks', 'espindola', 'falcao', '’s', 'close', 'friend', 'and', 'former', 'representative', 'told', 'as', 'colombia', '‘', 'we', 'speak', 'a', 'lot', 'i', 'am', 'not', 'going', 'to', 'tell', 'you', 'that', 'he', 'feels', 'happy', 'because', 'he', 'is', 'n’t', 'we', 'speak', 'many', 'times', 'and', 'we', 'cry', 'together', 'silvano', 'espindola', 'left', 'falcaos', 'former', 'agent', 'has', 'lifted', 'the', 'lid', 'on', 'the', 'colombians', 'emotional', 'struggle', 'louis', 'van', 'gaal', 'now', 'needs', 'to', 'decide', 'whether', 'he', 'wants', 'to', 'shell', 'out', '£', 'million', 'to', 'make', 'the', 'loan', 'permanent', 'falcao', 'left', 'battles', 'with', 'antonio', 'valencia', 'during', 'a', 'training', 'session', 'at', 'uniteds', 'aon', 'complex', 'on', 'friday', '‘', 'it', 'is', 'not', 'an', 'easy', 'situation', 'because', 'every', 'player', 'wants', 'to', 'play', 'and', 'every', 'goalscorer', 'wants', 'to', 'score', 'goals', 'it', '’s', 'what', '’s', 'normal', '‘', 'while', 'on', 'his', 'way', 'to', 'the', 'ground', 'to', 'play', 'that', 'match', 'with', 'the', 'youth', 'team', 'he', 'called', 'me', 'we', 'talked', 'for', 'about', 'minutes', 'while', 'he', 'arrived', 'at', 'the', 'stadium', 'and', 'he', 'told', 'me', '“', 'something', 'like', 'this', 'had', 'never', 'happened', 'to', 'me', '–', 'i', 'do', 'n’t', 'know', 'how', 'to', 'handle', 'the', 'situation', 'i', 'feel', 'weird', '”', '‘', 'he', 'was', 'a', 'little', 'fearful', 'because', 'he', 'is', 'afraid', 'of', 'those', 'matches', 'with', 'the', 'youth', 'teams', 'and', 'of', 'the', 'second', 'and', 'third', 'divisions', 'in', 'those', 'categories', 'they', 'are', 'used', 'to', 'whacking', 'and', 'going', 'in', 'hard', 'that', 'was', 'how', 'they', 'injured', 'him', 'in', 'france', 'with', 'a', 'team', 'from', 'the', 'fourth', 'division', '’']\n",
            "trg = ['silvano', 'espindola', 'has', 'spoken', 'about', 'radamel', 'falcaos', 'current', 'plight', 'the', 'players', 'former', 'agent', 'says', 'he', 'cries', 'down', 'the', 'phone', 'to', 'him', 'falcao', 'is', 'said', 'to', 'be', 'afraid', 'of', 'injury', 'playing', 'for', 'uniteds', 'under', 'squad', 'the', 'colombian', 'feels', 'weird', 'about', 'his', 'situation', 'at', 'manchester', 'united', 'click', 'here', 'for', 'all', 'the', 'latest', 'manchester', 'united', 'news']\n"
          ]
        }
      ],
      "source": [
        "example_idx = 12\n",
        "\n",
        "src = vars(CodeDataset.examples[example_idx])['Article']\n",
        "trg = vars(CodeDataset.examples[example_idx])['Highlights']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTJF0_ZujFZb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "\n",
        "        src = vars(datum)['Article']\n",
        "        trg = vars(datum)['Highlights']\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "\n",
        "        # cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "    return bleu_score(pred_trgs, trgs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "roug = Rouge()"
      ],
      "metadata": {
        "id": "oOez_MiirgA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rouge_score(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "\n",
        "        src = vars(datum)['Article']\n",
        "        trg = vars(datum)['Highlights']\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "\n",
        "        # cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(' '.join(pred_trg))\n",
        "        trgs.append(' '.join(trg))\n",
        "    return roug.get_scores(pred_trgs, trgs, avg = True)\n"
      ],
      "metadata": {
        "id": "6R6O7nzTr9ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = calculate_rouge_score(test, SRC, TRG, model, device)"
      ],
      "metadata": {
        "id": "-OyyMAXksssI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision Rouge 1, Rouge 2 and Rouge L: \", precision)\n",
        "print(\"Recall Rouge 1, Rouge 2 and Rouge L: \", recall)\n",
        "print(\"F1 Score Rouge 1, Rouge 2 and Rouge L: \", f1score)"
      ],
      "metadata": {
        "id": "BBoJ29-As6x-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}